{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kafka-streams-flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cells needed to run your application are included below. Make any changes and add your sources, analytics and outputs.\n",
    "\n",
    "### Documentation\n",
    "   - [Streams Python development guide](https://ibmstreams.github.io/streamsx.documentation/docs/latest/python/)\n",
    "   - [Streams Python API](https://streamsxtopology.readthedocs.io/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install  python packages\n",
    "Installs the required python packages with pip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --user python-dateutil==2.8.0\n",
    "!pip install --user streamsx.kafka>=1.9.0\n",
    "!pip install --user streamsx==1.14.13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup \n",
    "\n",
    "Sets up the Streams instance name and extracts the resources required for the Streams application to a local directory.\n",
    "\n",
    "In order to submit a Streams application you need to provide the name of the Streams instance.\n",
    "To change the instance for the Streams application:\n",
    "1. From the navigation menu, click **My instances**.\n",
    "2. Click the **Provisioned Instances** tab.\n",
    "3. Update the value of streams_instance_name in the cell below according to your Streams instance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from project_lib import Project\n",
    "import os, shutil, tarfile\n",
    "from icpd_core import icpd_util    \n",
    "\n",
    "def setup(archive, resource_path):\n",
    "    def extract_project_file(file, path):\n",
    "        project = Project.access()\n",
    "        if os.path.exists(path):\n",
    "            shutil.rmtree(path)\n",
    "        os.makedirs(path)\n",
    "        buffio = project.get_file(file, direct_storage=True)\n",
    "        tarfile.open(fileobj=buffio, mode=\"r:gz\").extractall(path)\n",
    "    extract_project_file(archive, resource_path)\n",
    "    os.chdir(resource_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streams_instance_name = \"streams\"\n",
    "cfg = icpd_util.get_service_instance_details(streams_instance_name)\n",
    "resource_path = \"streams_flows_notebooks/kafka_streams_flow_1597176040664\"\n",
    "setup(\"streams_flows_notebooks/kafka_streams_flow_1597176040664.tar.gz\", resource_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile flow_schemas\n",
    "\n",
    "from datetime import datetime\n",
    "from typing import NamedTuple\n",
    "\n",
    "DEFAULT_DATETIME = datetime.fromtimestamp(0)\n",
    "\n",
    "\n",
    "class SampleDataSchema(NamedTuple):\n",
    "    click_event_type: str = \"\"\n",
    "    customer_id: float = 0.0\n",
    "    time_stamp: datetime = DEFAULT_DATETIME\n",
    "    total_number_of_distinct_items_in_basket: float = 0.0\n",
    "    total_number_of_items_in_basket: float = 0.0\n",
    "    total_price_of_basket: float = 0.0\n",
    "    product_category: str = \"\"\n",
    "    product_name: str = \"\"\n",
    "    product_price: float = 0.0\n",
    "    session_duration: float = 0.0\n",
    "\n",
    "\n",
    "class JsonFromTuple1Schema(NamedTuple):\n",
    "    content: str = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from streamsx.topology.topology import Topology\n",
    "import flow_schemas\n",
    "\n",
    "import datetime\n",
    "import json\n",
    "from lib.error_utils import TupleError\n",
    "import lib.file_utils as file_utils\n",
    "from lib.sampledata.sample_data_producer import SampleDataProducer\n",
    "from lib.type_adapter import adapt_if_needed as _adapt_if_needed\n",
    "import os\n",
    "import streamsx.kafka as kafka\n",
    "import time\n",
    "import typing\n",
    "\n",
    "\n",
    "# ================================================================================\n",
    "# MAIN\n",
    "\n",
    "def build_flow():\n",
    "    topo = Topology(name='kafka_streams_flow', namespace=os.environ.get('USER', 'flow'))\n",
    "    topo.name_to_runtime_id = name_mapping().get\n",
    "\n",
    "    topo.add_pip_package('python-dateutil==2.8.0')\n",
    "    topo.add_pip_package('streamsx.kafka>=1.9.0')\n",
    "\n",
    "    sample_data_stream = add_sample_data(topo)  # Node: \"Sample Data\"\n",
    "    kafka_stream = add_kafka(sample_data_stream)  # Node: \"Kafka\"\n",
    "\n",
    "    add_views(topo)\n",
    "    return topo\n",
    "\n",
    "\n",
    "# ================================================================================\n",
    "# Function for top-level operator: Sample Data\n",
    "def add_sample_data(topo):\n",
    "    return (\n",
    "        topo\n",
    "        .source(\n",
    "            generate_sample_data,\n",
    "            name='Sample Data')\n",
    "        .filter(\n",
    "            lambda event: True,\n",
    "            name='CompositeOutput1')\n",
    "    )\n",
    "\n",
    "\n",
    "# ================================================================================\n",
    "# Function for top-level operator: Kafka\n",
    "def add_kafka(stream):\n",
    "    connection = file_utils.read_from_json(os.path.abspath(\"connections/kafka_4560768a-c25f-49e7-9333-23726b8ae71e.json\"))\n",
    "\n",
    "    return (\n",
    "        stream\n",
    "        .map(\n",
    "            lambda event: {\n",
    "                'content':\n",
    "                    json.dumps({\n",
    "                        'click_event_type': event.click_event_type,\n",
    "                        'customer_id': event.customer_id,\n",
    "                        'time_stamp': event.time_stamp.isoformat(),\n",
    "                        'total_number_of_distinct_items_in_basket': event.total_number_of_distinct_items_in_basket,\n",
    "                        'total_number_of_items_in_basket': event.total_number_of_items_in_basket,\n",
    "                        'total_price_of_basket': event.total_price_of_basket,\n",
    "                        'product_category': event.product_category,\n",
    "                        'product_name': event.product_name,\n",
    "                        'product_price': event.product_price,\n",
    "                        'session_duration': event.session_duration\n",
    "                    })\n",
    "            },\n",
    "            name='JsonFromTuple1',\n",
    "            schema=flow_schemas.JsonFromTuple1Schema)\n",
    "        .for_each(\n",
    "            kafka.KafkaProducer(\n",
    "                config={\n",
    "                    'bootstrap.servers': connection['brokers'],\n",
    "                    'security.protocol': connection['security_protocol'],\n",
    "                    'sasl.mechanism': connection['sasl_mechanism'],\n",
    "                    'sasl.jaas.config': f'org.apache.kafka.common.security.plain.PlainLoginModule required username=\"{connection[\"username\"]}\" password=\"{connection[\"api_key\"]}\";'\n",
    "                },\n",
    "                message_attribute_name='content',\n",
    "                topic='clicks'),\n",
    "            name='Kafka')\n",
    "    )\n",
    "\n",
    "\n",
    "# ================================================================================\n",
    "# Operator-specific global code, such as filter classes:\n",
    "\n",
    "def generate_sample_data() -> typing.Iterable[flow_schemas.SampleDataSchema]:\n",
    "    producer = SampleDataProducer(['clickStreamSampleData'])\n",
    "    offset = 0\n",
    "    while True:\n",
    "        sample_events = producer.get_events('clickStreamSampleData', offset, 1)\n",
    "        sample_event = sample_events[0]\n",
    "        offset += 1\n",
    "\n",
    "        errors = []\n",
    "        try:\n",
    "            output_event = flow_schemas.SampleDataSchema(\n",
    "                click_event_type=_adapt_if_needed(sample_event.click_event_type, str, 'click_event_type', 'Text', errors),\n",
    "                customer_id=_adapt_if_needed(sample_event.customer_id, float, 'customer_id', 'Number', errors),\n",
    "                time_stamp=_adapt_if_needed(sample_event.time_stamp, datetime.datetime, 'time_stamp', 'Date', errors),\n",
    "                total_number_of_distinct_items_in_basket=_adapt_if_needed(sample_event.total_number_of_distinct_items_in_basket, float, 'total_number_of_distinct_items_in_basket', 'Number', errors),\n",
    "                total_number_of_items_in_basket=_adapt_if_needed(sample_event.total_number_of_items_in_basket, float, 'total_number_of_items_in_basket', 'Number', errors),\n",
    "                total_price_of_basket=_adapt_if_needed(sample_event.total_price_of_basket, float, 'total_price_of_basket', 'Number', errors),\n",
    "                product_category=_adapt_if_needed(sample_event.product_category, str, 'product_category', 'Text', errors),\n",
    "                product_name=_adapt_if_needed(sample_event.product_name, str, 'product_name', 'Text', errors),\n",
    "                product_price=_adapt_if_needed(sample_event.product_price, float, 'product_price', 'Number', errors),\n",
    "                session_duration=_adapt_if_needed(sample_event.session_duration, float, 'session_duration', 'Number', errors)\n",
    "            )\n",
    "            if len(errors) > 0:\n",
    "                raise ValueError('\\n'.join(errors))\n",
    "            yield output_event\n",
    "        except Exception as err:\n",
    "            TupleError(operation_id='Sample Data', message=str(err))\n",
    "\n",
    "        time.sleep(0.05)\n",
    "\n",
    "\n",
    "# ================================================================================\n",
    "# Utils:\n",
    "\n",
    "def add_views(topo):\n",
    "    name_to_id = name_mapping()\n",
    "    for name, stream in topo.streams.items():\n",
    "        stream_id = name_to_id.get(name)\n",
    "        if stream_id and stream_id.endswith('__Composite_Output_Id'):\n",
    "            stream.view(name=stream_id + \"__output\")\n",
    "\n",
    "\n",
    "def name_mapping():\n",
    "    return {\n",
    "        'Sample Data': 'Sample_Data',\n",
    "        'CompositeOutput1': 'Sample_Data__Composite_Output_Id',\n",
    "        'JsonFromTuple1': 'JsonFromTuple1',\n",
    "        'Kafka': 'Kafka'\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit the application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamsx\n",
    "import datetime\n",
    "from streamsx.topology.context import ContextTypes, JobConfig\n",
    "from streamsx.topology import context\n",
    "\n",
    "def submit_app():\n",
    "    cfg[context.ConfigParams.SSL_VERIFY] = False\n",
    "    app = build_flow()\n",
    "\n",
    "    dt = datetime.datetime.now().strftime('%F_%T')\n",
    "    \n",
    "    job_config = JobConfig(job_name=f'{app.namespace}:{app.name}:{dt}', tracing='info')\n",
    "    job_config.add(cfg)\n",
    "\n",
    "    shutil.copytree('lib', 'python/modules/lib')\n",
    "    app.add_file_dependency('python', 'opt')\n",
    "\n",
    "    submission_result = streamsx.topology.context.submit(ContextTypes.DISTRIBUTED, app, config=cfg)\n",
    "    streams_job = submission_result.job\n",
    "    print(\"JobId: \", streams_job.id, \"\\nJob name: \", streams_job.name)\n",
    "submit_app()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete the resource directory (Optional)\n",
    "Cleans up the resource folders used in this application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleanup()\n",
    "# import shutil\n",
    "# os.chdir(os.environ['PWD'])\n",
    "# if os.path.exists(resource_path):\n",
    "#     shutil.rmtree(resource_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
